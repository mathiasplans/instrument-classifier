{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutionl Neural Network\n",
    "\n",
    "In this notebook we try to use CNN for instrument classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Remove index\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# 1-hotify instrument\n",
    "instrdummy = pd.get_dummies(data.instrument)\n",
    "instrdummy\n",
    "\n",
    "for c in instrdummy.columns:\n",
    "    data[c] = instrdummy[c]\n",
    "    \n",
    "data = data.drop('instrument', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of samples in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpls = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCrest_input = keras.Input(shape=(smpls,), name='SCrest')\n",
    "SCentroid_input = keras.Input(shape=(smpls,), name='SCentroid')\n",
    "SKurtosis_input = keras.Input(shape=(smpls,), name='SKurtosis')\n",
    "SMean_input = keras.Input(shape=(smpls,), name='SMean')\n",
    "SRolloff_input = keras.Input(shape=(smpls,), name='SRolloff')\n",
    "SVariance_input = keras.Input(shape=(smpls,), name='SVariance')\n",
    "SSkewness_input = keras.Input(shape=(smpls,), name='SSkewness')\n",
    "SFlux_input = keras.Input(shape=(smpls,), name='SFlux')\n",
    "mfcd_input = keras.Input(shape=(smpls,), name='CeptralFeatures')\n",
    "zcr_input = keras.Input(shape=(smpls,), name='TemporalFeatures')\n",
    "inps = [SCrest_input, SCentroid_input, SKurtosis_input, SMean_input, SRolloff_input, SVariance_input, SSkewness_input, SFlux_input, mfcd_input, zcr_input]\n",
    "\n",
    "def soloLayer(inputlayer):\n",
    "    r = layers.Reshape((smpls,1))(inputlayer)\n",
    "    conv1 = layers.Conv1D(filters=128, kernel_size=5)(r)\n",
    "    conv2 = layers.Conv1D(filters=64, kernel_size=3)(conv1)\n",
    "    max11 = layers.MaxPooling1D(3)(conv2)\n",
    "    batch2 = layers.BatchNormalization()(max11)\n",
    "    \n",
    "    return batch2\n",
    "\n",
    "def merge(ls):\n",
    "    flats = [layers.Flatten()(l) for l in ls]\n",
    "    \n",
    "    return layers.concatenate(flats)\n",
    "\n",
    "input_merged = merge([soloLayer(il) for il in inps])\n",
    "\n",
    "d2 = layers.Dense(64, 'tanh')(input_merged)\n",
    "d3 = layers.Dense(32)(d2)\n",
    "dr2 = layers.Dropout(.05)(d3)\n",
    "\n",
    "out = layers.Dense(8, 'softmax')(dr2)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=inps+[timbral_input],\n",
    "    outputs=out\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into separate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_scre, test_scre, train_scen, test_scen, train_skur, test_skur, train_smea, test_smea, train_srol, test_srol, train_svar, test_svar, train_sskew, test_sskew, train_sflu, test_sflu, train_mfcd, test_mfcd, train_zcr, test_zcr, train_y, test_y = train_test_split(\n",
    "    data.SCrest,\n",
    "    data.SCentroid,\n",
    "    data.SKurtosis,\n",
    "    data.SMean,\n",
    "    data.SRolloff,\n",
    "    data.SVariance,\n",
    "    data.SSkewness,\n",
    "    data.SFlux,\n",
    "    data.MFCD,\n",
    "    data.ZCR,\n",
    "    data[['cel', 'cla', 'flu', 'gac', 'pia', 'sax', 'tru', 'vio']],\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "train_X = [train_scre, train_scen, train_skur, train_smea, train_srol, train_svar, train_sskew, train_sflu, train_mfcd, train_zcr]\n",
    "test_X = [test_scre, test_scen, test_skur, test_smea, test_srol, test_svar, test_sskew, test_sflu, test_mfcd, test_zcr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the data suitable for Keras consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "train_X_list = []\n",
    "for x in train_X:\n",
    "    train_X_list += [np.asarray([K.cast_to_floatx(a) for a in x.values])]\n",
    "    \n",
    "train_y_list = K.cast_to_floatx(train_y.values.astype('float32'))\n",
    "\n",
    "test_X_list = []\n",
    "for x in test_X:\n",
    "    test_X_list += [np.asarray([K.cast_to_floatx(a) for a in x.values])]\n",
    "    \n",
    "test_y_list = K.cast_to_floatx(test_y.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make so that the Tensorflow functions run eagerly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teach the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=train_X_list, \n",
    "    y=train_y_list, \n",
    "    batch_size=128, epochs=17,\n",
    "    validation_data=(test_X_list, test_y_list)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(test_X_list), axis=1)\n",
    "y_actual = np.argmax(test_y_list, axis=1)\n",
    "cm = confusion_matrix(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, index = [i for i in ['cel', 'cla', 'flu', 'gac', 'pia', 'sax', 'tru', 'vio']],\n",
    "                       columns = [i for i in ['cel', 'cla', 'flu', 'gac', 'pia', 'sax', 'tru', 'vio']])\n",
    "\n",
    "plt.figure(figsize = (11,9))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
